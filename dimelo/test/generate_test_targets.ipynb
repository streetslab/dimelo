{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modkit found with expected version 0.2.4\n",
      "Reference genome already downloaded.\n",
      "Input bam already retagged.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from inspect import signature\n",
    "\n",
    "import dimelo\n",
    "from dimelo import parse_bam, load_processed\n",
    "from dimelo.test import RelativePath,DiMeLoParsingTestCase,filter_kwargs_for_func\n",
    "\n",
    "# Base input and output directories\n",
    "test_data_dir = Path('./data')\n",
    "output_dir = test_data_dir / 'test_targets'\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "region = 'chr1:9167177-9169177'\n",
    "\n",
    "# Paths to input files\n",
    "ctcf_bam_file = test_data_dir / 'ctcf_demo.sorted.bam'\n",
    "# ctcf_guppy_bam_file = test_data_dir / 'winnowmap_guppy_merge_subset.updated.bam'\n",
    "ctcf_target_regions = RelativePath(test_data_dir / 'ctcf_demo_peak.bed')\n",
    "ctcf_off_target_regions = RelativePath(test_data_dir / 'ctcf_demo_not_peak.bed')\n",
    "ref_genome_file = Path('./output/chm13.draft_v1.0.fasta')\n",
    "ctcf_bam_file_updated =  RelativePath('./output/ctcf_demo.updated.bam')\n",
    "output_dir = RelativePath(output_dir)\n",
    "\n",
    "# Set up input files\n",
    "DiMeLoParsingTestCase.setup_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or load test matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-existing test matrix\n",
    "\n",
    "This code should be used if you are trying to update only some test cases. Tests can only be updated by category in rest of the code. Only run categories where you are confident that you haven't broken any functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(RelativePath('data/test_targets/test_matrix.pickle')).exists():\n",
    "    with open(RelativePath('data/test_targets/test_matrix.pickle'), 'rb') as file:\n",
    "        test_matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fresh test matrix\n",
    "\n",
    "This code should be used if you are re-creating your test matrix from scratch: you should know everything is working correctly and plan to run all the remaining cells in the notebook to get all the different test cases covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = {\n",
    "    'megalodon_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':None,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':10,\n",
    "            'title':'megalodon_single_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_and_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_and_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[region,ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':100,\n",
    "            'title':'megalodon_single_and_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_nothresh':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_nothresh',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':None,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_single_nothresh',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parse_bam outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611128d5b73a45198166ba4727a8d611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e773dea6234131a894ed77023a7b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee76bb6059a49e69b5ae98214122a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b6d223f744c628babc10620b56060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3bd420756a49aba99b4584797dfe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9797243a66f6497b9081686ae6dd616a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694e5617f0da4aca8acd4a760081a147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfde0b6722f4c78b973518ee2561c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b49b52e41a44feb83393233e93b708f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "No base modification threshold provided. Using adaptive threshold selection via modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4095447bf894c8cb67bdf4ffe1ed9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9ac561ff71434d8dbf95ccdbed67f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e65c134082e44d3bf71219755f78a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_pileup = filter_kwargs_for_func(parse_bam.pileup,kwargs)\n",
    "    pileup_file, pileup_regions = parse_bam.pileup(\n",
    "        **kwargs_pileup,\n",
    "        ref_genome = ref_genome_file,\n",
    "    )\n",
    "    results['pileup'] = (RelativePath(pileup_file),RelativePath(pileup_regions))\n",
    "\n",
    "# pileup_file, pileup_regions = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_merged_regions',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=[ctcf_target_regions,ctcf_off_target_regions],\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=1000,\n",
    "# )\n",
    "# pileup_file_one, pileup_regions_one = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_one_region',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=region,\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocating requested 1 cores.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8f167a176d4cd7a4a4b817bb12af27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec9775cf04142b4839299c02b7d35b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b5129b5c9f4b9882af03122c0c7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d690054360e4defaf5ba69659d33393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 26 from reads.A,0.txt into reads.combined_basemods.h5, new size 26   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e63a366259847c0973a4da44f759471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8efffae1a74c8983cdf77a94c992d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f227c86830d482a889925b6529fc376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b29836a7472454f8ac019923c43ab40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 26 from reads.CG,0.txt into reads.combined_basemods.h5, new size 52   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocating requested 1 cores.\n",
      "No valid base modification threshold provided. Raw probs will be saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f515265845451d951b59d8749a4f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e4b28456624806b5207cc96173d220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3df400b11714a90afc8474f56194dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f13fd32a335481ca281e3e7a40bbe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 28 from reads.A,0.txt into reads.combined_basemods.h5, new size 28   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062f19f91e7d4ad8833dc4cb3a41c81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1181337ab6074913801d925c3f2391d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eee4072123e45d592ab3f589b1f0668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7773ca8ded478ea18f9ea447e1ce93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 28 from reads.CG,0.txt into reads.combined_basemods.h5, new size 56   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_extract = filter_kwargs_for_func(parse_bam.extract,kwargs)\n",
    "    if kwargs['regions']==region: # for now, we only want to extract with the single region due to output file size\n",
    "        extract_file, extract_regions = parse_bam.extract(\n",
    "            **kwargs_extract,\n",
    "            ref_genome = ref_genome_file,\n",
    "            cores=1,\n",
    "        )\n",
    "        results['extract'] = (RelativePath(extract_file),RelativePath(extract_regions))\n",
    "    else:\n",
    "        results['extract'] = (None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate load_processed outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_counts_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_counts_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_counts_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_counts_from_bedmethyl'][motif] = load_processed.pileup_counts_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif = motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_vectors_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_vectors_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_vectors_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_vectors_from_bedmethyl'][motif] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif=motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_vectors_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    extract_file,regions_bed = results['extract']\n",
    "    if extract_file is not None and regions_bed is not None:\n",
    "        kwargs_func = filter_kwargs_for_func(load_processed.read_vectors_from_hdf5,kwargs)\n",
    "        read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "            file=extract_file,\n",
    "            **kwargs_func,\n",
    "        )        \n",
    "        read_data_dict = {}\n",
    "        # Pull out the data from the first read\n",
    "        for idx,dataset in enumerate(datasets):\n",
    "            for read_data in read_data_list:\n",
    "                read_data_dict[dataset] = read_data[idx]\n",
    "                break    \n",
    "        results['read_vectors_from_hdf5'] = read_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save text matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megalodon_peaks_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x14f25fbd0>, <dimelo.test.RelativePath object at 0x1049ceb10>)\n",
      "extract\n",
      "(None, None)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (15443, 314114), 'CG,0': (916, 42934)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([ 9,  7,  8, ..., 15, 15, 10]), array([1338, 1322, 1253, ..., 1367, 1257, 1235])), 'CG,0': (array([ 8, 30,  9, ...,  9,  8,  2]), array([160, 195, 155, ..., 116,  81,  31]))}\n",
      "megalodon_single_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x14d747f10>, <dimelo.test.RelativePath object at 0x14c1b00d0>)\n",
      "extract\n",
      "(<dimelo.test.RelativePath object at 0x14d7c6cd0>, <dimelo.test.RelativePath object at 0x158f0b050>)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (127, 12254), 'CG,0': (206, 950)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([0, 0, 0, ..., 0, 0, 0]), array([ 0, 12,  0, ..., 13,  0, 13])), 'CG,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))}\n",
      "read_vectors_from_hdf5\n",
      "{'chromosome': 'chr1', 'mod_vector': array([False, False, False, ..., False, False, False]), 'motif': 'A,0', 'read_end': 9206582, 'read_name': 'bc8057e5-935b-4a1a-a0de-f7a4c0dbe4bb', 'read_start': 9127032, 'strand': '-', 'val_vector': array([False, False, False, ..., False, False,  True]), 'region_start': 9167177, 'region_end': 9169177, 'A,0_mod_fraction': 0.009505703422053232, 'CG,0_mod_fraction': 0.35135135135135137}\n",
      "megalodon_single_and_peaks_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x1582a19d0>, <dimelo.test.RelativePath object at 0x14dea3490>)\n",
      "extract\n",
      "(None, None)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (15570, 326368), 'CG,0': (1122, 43884)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([ 9,  7,  8, ..., 15, 15, 10]), array([1338, 1329, 1260, ..., 1367, 1257, 1244])), 'CG,0': (array([ 8, 30,  9, ...,  9,  8,  2]), array([160, 195, 155, ..., 116,  81,  31]))}\n",
      "megalodon_single_nothresh outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x14deb7350>, <dimelo.test.RelativePath object at 0x1592f9b90>)\n",
      "extract\n",
      "(<dimelo.test.RelativePath object at 0x158f0afd0>, <dimelo.test.RelativePath object at 0x1593b98d0>)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (243, 12254), 'CG,0': (325, 950)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 7, 7, ..., 0, 0, 9])), 'CG,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))}\n",
      "read_vectors_from_hdf5\n",
      "{'chromosome': 'chr1', 'mod_vector': array([0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.001953],\n",
      "      dtype=float16), 'motif': 'A,0', 'read_end': 9206582, 'read_name': 'bc8057e5-935b-4a1a-a0de-f7a4c0dbe4bb', 'read_start': 9127032, 'strand': '-', 'val_vector': array([0, 0, 0, ..., 0, 0, 1]), 'region_start': 9163177, 'region_end': 9173177, 'A,0_mod_fraction': 0.050824175824175824, 'CG,0_mod_fraction': 0.22969314079422382}\n"
     ]
    }
   ],
   "source": [
    "for test_name,entries in test_matrix.items():\n",
    "    print(test_name,'outputs')\n",
    "    for key,value in entries[1].items():\n",
    "        print(key)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_targets/test_matrix.pickle', 'wb') as file:\n",
    "    pickle.dump(test_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_dict = defaultdict(dict)\n",
    "# vectors_dict = defaultdict(dict)\n",
    "# binarized_reads_dict = defaultdict(dict)\n",
    "# prob_reads_dict = defaultdict(dict)\n",
    "# for motif in ['A,0','CG,0']:\n",
    "#     # Extract the total counts for the motif/regions\n",
    "#     for regions in [region,ctcf_target_regions]:\n",
    "#         counts_dict[motif][regions] = load_processed.pileup_counts_from_bedmethyl(\n",
    "#             bedmethyl_file = pileup_file,\n",
    "#             motif = motif,\n",
    "#             regions = regions\n",
    "#         )\n",
    "#     # Extract counts profiles for the motif/regions\n",
    "#     vectors_dict[motif][regions] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "#         bedmethyl_file = pileup_file,\n",
    "#         motif = motif,\n",
    "#         regions = regions,\n",
    "#         window_size = 10, # Trim/extend regions to same size    \n",
    "#     )\n",
    "#     # Extract binarized read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file, # binarized modification calls\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break    \n",
    "#     binarized_reads_dict[motif][regions] = read_data_dict\n",
    "#     # Extract probability read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file_no_thresh, # raw modification probabilities\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     # Print out the data from the first read\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break\n",
    "#     prob_reads_dict[motif][regions] = read_data_dict\n",
    "# data_struct = (counts_dict,vectors_dict,binarized_reads_dict,prob_reads_dict)\n",
    "# # Pickle the combined structure to a file\n",
    "# with open(target_paths_dict['load_processed'], 'wb') as file:\n",
    "#     pickle.dump(data_struct, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimelo_modkit_parsing",
   "language": "python",
   "name": "dimelo_modkit_parsing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
