{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modkit found with expected version 0.2.4\n",
      "Reference genome already downloaded.\n",
      "Input bam already retagged.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from inspect import signature\n",
    "\n",
    "import dimelo\n",
    "from dimelo import parse_bam, load_processed\n",
    "from dimelo.test import RelativePath,DiMeLoParsingTestCase,filter_kwargs_for_func\n",
    "\n",
    "# Base input and output directories\n",
    "test_data_dir = Path('./data')\n",
    "output_dir = test_data_dir / 'test_targets'\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "region = 'chr1:9167177-9169177'\n",
    "\n",
    "# Paths to input files\n",
    "ctcf_bam_file = test_data_dir / 'ctcf_demo.sorted.bam'\n",
    "# ctcf_guppy_bam_file = test_data_dir / 'winnowmap_guppy_merge_subset.updated.bam'\n",
    "ctcf_target_regions = RelativePath(test_data_dir / 'ctcf_demo_peak.bed')\n",
    "ctcf_off_target_regions = RelativePath(test_data_dir / 'ctcf_demo_not_peak.bed')\n",
    "ref_genome_file = Path('./output/chm13.draft_v1.0.fasta')\n",
    "ctcf_bam_file_updated =  RelativePath('./output/ctcf_demo.updated.bam')\n",
    "output_dir = RelativePath(output_dir)\n",
    "\n",
    "# Set up input files\n",
    "DiMeLoParsingTestCase.setup_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or load test matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-existing test matrix\n",
    "\n",
    "This code should be used if you are trying to update only some test cases. Tests can only be updated by category in rest of the code. Only run categories where you are confident that you haven't broken any functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(RelativePath('data/test_targets/test_matrix.pickle')).exists():\n",
    "    with open(RelativePath('data/test_targets/test_matrix.pickle'), 'rb') as file:\n",
    "        test_matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fresh test matrix\n",
    "\n",
    "This code should be used if you are re-creating your test matrix from scratch: you should know everything is working correctly and plan to run all the remaining cells in the notebook to get all the different test cases covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = {\n",
    "    'megalodon_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':None,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':10,\n",
    "            'title':'megalodon_single_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_and_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_and_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[region,ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':100,\n",
    "            'title':'megalodon_single_and_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_nothresh':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_nothresh',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':None,\n",
    "            'window_size':5000,\n",
    "            'sort_by':['read_start','read_name','motif'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_single_nothresh',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parse_bam outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8f603725d147c9ba7a257a0333abff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6079645cfb40f99b0f043d3d3545e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d35a89babde4da995fa5c5ce3f99961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf78eba534d14ecba8e43807814f428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63275349aa6745b8a7e1b2bcea926614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6d3c238bfc41bdad5f0a3af0c50a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820dd62bda0844508c462e53346cbea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3437dbf0014faf8a9392ebe56b3a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5643f8398e34384bf40af107a393110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "No base modification threshold provided. Using adaptive threshold selection via modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d1751a34264e27833aaf6b41693b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3194f04911346dcbeace86570b19866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e2c524ecce468080c47777a377cf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_pileup = filter_kwargs_for_func(parse_bam.pileup,kwargs)\n",
    "    pileup_file, pileup_regions = parse_bam.pileup(\n",
    "        **kwargs_pileup,\n",
    "        ref_genome = ref_genome_file,\n",
    "    )\n",
    "    results['pileup'] = (RelativePath(pileup_file),RelativePath(pileup_regions))\n",
    "\n",
    "# pileup_file, pileup_regions = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_merged_regions',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=[ctcf_target_regions,ctcf_off_target_regions],\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=1000,\n",
    "# )\n",
    "# pileup_file_one, pileup_regions_one = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_one_region',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=region,\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318601e2db52431ea87ad509db2af0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d227fe3d0db4b3baf3ffef7d3c9b5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66543d5093f64b91b58b8371b0c1ec8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c678b7441f7a4288a5fd6352cae8c352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 26 from reads.A,0.txt into reads.combined_basemods.h5, new size 26   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba52d667cd34535ab709745168002b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb4d8e70e3d47ed8e22954c54002a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81015e0842614812b861879b8f31530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c3aa2d8f647158684fdb936b4a9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 26 from reads.CG,0.txt into reads.combined_basemods.h5, new size 52   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "No valid base modification threshold provided. Raw probs will be saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e34be1d4c264047934cc235cfe7dcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aba8e63b18470491b591b77801acfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d265dd528b8d4172aa92ed6dc4fab6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c235d5dc970e43f1988793f7fb1c248a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 28 from reads.A,0.txt into reads.combined_basemods.h5, new size 28   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5136bee343e34492b529b89316e4cb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603fae168c304382aef5146af1bd6b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4366b794b8ab48a398c93c2f13ee0a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0577adab5ad54fb8b33db1d40d9fa589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 28 from reads.CG,0.txt into reads.combined_basemods.h5, new size 56   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_extract = filter_kwargs_for_func(parse_bam.extract,kwargs)\n",
    "    if kwargs['regions']==region: # for now, we only want to extract with the single region due to output file size\n",
    "        extract_file, extract_regions = parse_bam.extract(\n",
    "            **kwargs_extract,\n",
    "            ref_genome = ref_genome_file,\n",
    "        )\n",
    "        results['extract'] = (RelativePath(extract_file),RelativePath(extract_regions))\n",
    "    else:\n",
    "        results['extract'] = (None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate load_processed outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_counts_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_counts_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_counts_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_counts_from_bedmethyl'][motif] = load_processed.pileup_counts_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif = motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_vectors_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_vectors_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_vectors_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_vectors_from_bedmethyl'][motif] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif=motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_vectors_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    extract_file,regions_bed = results['extract']\n",
    "    if extract_file is not None and regions_bed is not None:\n",
    "        kwargs_func = filter_kwargs_for_func(load_processed.read_vectors_from_hdf5,kwargs)\n",
    "        read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "            file=extract_file,\n",
    "            **kwargs_func,\n",
    "        )        \n",
    "        read_data_dict = {}\n",
    "        # Pull out the data from the first read\n",
    "        for idx,dataset in enumerate(datasets):\n",
    "            for read_data in read_data_list:\n",
    "                read_data_dict[dataset] = read_data[idx]\n",
    "                break    \n",
    "        results['read_vectors_from_hdf5'] = read_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save text matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megalodon_peaks_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x11b3b8e10>, <dimelo.test.RelativePath object at 0x103d572d0>)\n",
      "extract\n",
      "(None, None)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (15443, 314114), 'CG,0': (916, 42934)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([ 9,  7,  8, ..., 15, 15, 10]), array([1338, 1322, 1253, ..., 1367, 1257, 1235])), 'CG,0': (array([ 8, 30,  9, ...,  9,  8,  2]), array([160, 195, 155, ..., 116,  81,  31]))}\n",
      "megalodon_single_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x11e428e50>, <dimelo.test.RelativePath object at 0x103c33850>)\n",
      "extract\n",
      "(<dimelo.test.RelativePath object at 0x1287bb550>, <dimelo.test.RelativePath object at 0x11dc0bbd0>)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (127, 12254), 'CG,0': (206, 950)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([0, 0, 0, ..., 0, 0, 0]), array([ 0, 12,  0, ..., 13,  0, 13])), 'CG,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))}\n",
      "read_vectors_from_hdf5\n",
      "{'chromosome': 'chr1', 'mod_vector': array([False, False, False, ..., False, False, False]), 'motif': 'A,0', 'read_end': 9206582, 'read_name': 'bc8057e5-935b-4a1a-a0de-f7a4c0dbe4bb', 'read_start': 9127032, 'strand': '-', 'val_vector': array([False, False, False, ..., False, False,  True]), 'region_start': 9167177, 'region_end': 9169177, 'A,0_mod_fraction': 0.009505703422053232, 'CG,0_mod_fraction': 0.35135135135135137}\n",
      "megalodon_single_and_peaks_190 outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x11f7ea290>, <dimelo.test.RelativePath object at 0x103c7a610>)\n",
      "extract\n",
      "(None, None)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (15570, 326368), 'CG,0': (1122, 43884)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([ 9,  7,  8, ..., 15, 15, 10]), array([1338, 1329, 1260, ..., 1367, 1257, 1244])), 'CG,0': (array([ 8, 30,  9, ...,  9,  8,  2]), array([160, 195, 155, ..., 116,  81,  31]))}\n",
      "megalodon_single_nothresh outputs\n",
      "pileup\n",
      "(<dimelo.test.RelativePath object at 0x11d32e610>, <dimelo.test.RelativePath object at 0x103c53810>)\n",
      "extract\n",
      "(<dimelo.test.RelativePath object at 0x1288c5050>, <dimelo.test.RelativePath object at 0x1288d5b90>)\n",
      "pileup_counts_from_bedmethyl\n",
      "{'A,0': (243, 12254), 'CG,0': (325, 950)}\n",
      "pileup_vectors_from_bedmethyl\n",
      "{'A,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 7, 7, ..., 0, 0, 9])), 'CG,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))}\n",
      "read_vectors_from_hdf5\n",
      "{'chromosome': 'chr1', 'mod_vector': array([0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.001953],\n",
      "      dtype=float16), 'motif': 'A,0', 'read_end': 9206582, 'read_name': 'bc8057e5-935b-4a1a-a0de-f7a4c0dbe4bb', 'read_start': 9127032, 'strand': '-', 'val_vector': array([0., 0., 0., ..., 0., 0., 1.], dtype=float16), 'region_start': 9163177, 'region_end': 9173177, 'A,0_mod_fraction': 0.0508, 'CG,0_mod_fraction': 0.2297}\n"
     ]
    }
   ],
   "source": [
    "for test_name,entries in test_matrix.items():\n",
    "    print(test_name,'outputs')\n",
    "    for key,value in entries[1].items():\n",
    "        print(key)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_targets/test_matrix.pickle', 'wb') as file:\n",
    "    pickle.dump(test_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_dict = defaultdict(dict)\n",
    "# vectors_dict = defaultdict(dict)\n",
    "# binarized_reads_dict = defaultdict(dict)\n",
    "# prob_reads_dict = defaultdict(dict)\n",
    "# for motif in ['A,0','CG,0']:\n",
    "#     # Extract the total counts for the motif/regions\n",
    "#     for regions in [region,ctcf_target_regions]:\n",
    "#         counts_dict[motif][regions] = load_processed.pileup_counts_from_bedmethyl(\n",
    "#             bedmethyl_file = pileup_file,\n",
    "#             motif = motif,\n",
    "#             regions = regions\n",
    "#         )\n",
    "#     # Extract counts profiles for the motif/regions\n",
    "#     vectors_dict[motif][regions] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "#         bedmethyl_file = pileup_file,\n",
    "#         motif = motif,\n",
    "#         regions = regions,\n",
    "#         window_size = 10, # Trim/extend regions to same size    \n",
    "#     )\n",
    "#     # Extract binarized read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file, # binarized modification calls\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break    \n",
    "#     binarized_reads_dict[motif][regions] = read_data_dict\n",
    "#     # Extract probability read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file_no_thresh, # raw modification probabilities\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     # Print out the data from the first read\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break\n",
    "#     prob_reads_dict[motif][regions] = read_data_dict\n",
    "# data_struct = (counts_dict,vectors_dict,binarized_reads_dict,prob_reads_dict)\n",
    "# # Pickle the combined structure to a file\n",
    "# with open(target_paths_dict['load_processed'], 'wb') as file:\n",
    "#     pickle.dump(data_struct, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimelo_modkit_parsing",
   "language": "python",
   "name": "dimelo_modkit_parsing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
