{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH does not include the conda environment /bin folder. Adding /global/home/users/dixonluinenburg/.conda/envs/dimelo_modkit_3.11/bin.\n",
      "PATH is now /global/home/users/dixonluinenburg/.conda/envs/dimelo_modkit_3.11/bin:/global/software/sl-7.x86_64/modules/langs/python/3.10/bin:/global/software/sl-7.x86_64/modules/tools/sq/0.1.0/bin:/global/software/sl-7.x86_64/modules/tools/emacs/25.1/bin:/global/software/sl-7.x86_64/modules/tools/vim/7.4/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/global/home/groups/allhands/bin:/global/home/users/dixonluinenburg/bin\n",
      "modkit found with expected version 0.2.4\n",
      "Reference genome already downloaded.\n",
      "Input bam already retagged.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from inspect import signature\n",
    "\n",
    "import dimelo\n",
    "from dimelo import parse_bam, load_processed\n",
    "from dimelo.test import RelativePath,DiMeLoParsingTestCase,filter_kwargs_for_func\n",
    "\n",
    "# Base input and output directories\n",
    "test_data_dir = Path('./data')\n",
    "output_dir = test_data_dir / 'test_targets'\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "region = 'chr14:17376348-17378348'\n",
    "\n",
    "# Paths to input files\n",
    "ctcf_bam_file = test_data_dir / 'ctcf_demo.sorted.bam'\n",
    "# ctcf_guppy_bam_file = test_data_dir / 'winnowmap_guppy_merge_subset.updated.bam'\n",
    "ctcf_target_regions = RelativePath(test_data_dir / 'ctcf_demo_peak.bed')\n",
    "ctcf_off_target_regions = RelativePath(test_data_dir / 'ctcf_demo_not_peak.bed')\n",
    "ref_genome_file = Path('./output/chm13.draft_v1.0.fasta')\n",
    "ctcf_bam_file_updated =  RelativePath('./output/ctcf_demo.updated.bam')\n",
    "output_dir = RelativePath(output_dir)\n",
    "\n",
    "# Set up input files\n",
    "DiMeLoParsingTestCase.setup_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or load test matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-existing test matrix\n",
    "\n",
    "This code should be used if you are trying to update only some test cases. Tests can only be updated by category in rest of the code. Only run categories where you are confident that you haven't broken any functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(RelativePath('data/test_targets/test_matrix.pickle')).exists():\n",
    "    with open(RelativePath('data/test_targets/test_matrix.pickle'), 'rb') as file:\n",
    "        test_matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fresh test matrix\n",
    "\n",
    "This code should be used if you are re-creating your test matrix from scratch: you should know everything is working correctly and plan to run all the remaining cells in the notebook to get all the different test cases covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = {\n",
    "    'megalodon_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':1000,\n",
    "            'sort_by':['chromosome','read_start','read_name'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':None,\n",
    "            'sort_by':['chromosome','read_start','read_name'],\n",
    "            'smooth_window':10,\n",
    "            'title':'megalodon_single_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_sinlge_and_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_and_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[region,ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':1000,\n",
    "            'sort_by':['chromosome','read_start','read_name'],\n",
    "            'smooth_window':100,\n",
    "            'title':'megalodon_single_and_peaks_190',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_nothresh':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_nothresh',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':None,\n",
    "            'window_size':None,\n",
    "            'sort_by':['chromosome','read_end','read_name'],\n",
    "            'smooth_window':1,\n",
    "            'title':'megalodon_single_nothresh',\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parse_bam outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 32 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc615c4c2908450ea055b85cf5fcb9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a364a7feb7b24e1d93a46f526d4db1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbcf90aac6d45219d139c280e4dafcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 32 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4484d5cf904eb090eecf3a0f04571b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cfeb73578e4e06b07ec439bf6b15bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adbdbaca929431b95f9dfee01faeba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_pileup = filter_kwargs_for_func(parse_bam.pileup,kwargs)\n",
    "    pileup_file, pileup_regions = parse_bam.pileup(\n",
    "        **kwargs_pileup,\n",
    "        ref_genome = ref_genome_file,\n",
    "    )\n",
    "    results['pileup'] = (RelativePath(pileup_file),RelativePath(pileup_regions))\n",
    "\n",
    "# pileup_file, pileup_regions = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_merged_regions',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=[ctcf_target_regions,ctcf_off_target_regions],\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=1000,\n",
    "# )\n",
    "# pileup_file_one, pileup_regions_one = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_one_region',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=region,\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 32 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc1e04498d842f7993d363767951138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9667880d5a8f4d7c92fcf5c528eed09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc29ddb47ea48728b433197b35b592d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1560f8a5e4074bb7b28796042459a56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.A,0.txt into reads.combined_basemods.h5, new size 24   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a774f2a617d425abd4c760ee693d121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380efe46051a4b349d44a71188832942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da49f9218d6443698f6e09a1eddc5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701de09472d54cc5bb968a29b1e036f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.CG,0.txt into reads.combined_basemods.h5, new size 48   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    kwargs_extract = filter_kwargs_for_func(parse_bam.extract,kwargs)\n",
    "    if kwargs['regions']==region: # for now, we only want to extract with the single region due to output file size\n",
    "        extract_file, extract_regions = parse_bam.extract(\n",
    "            **kwargs_extract,\n",
    "            ref_genome = ref_genome_file,\n",
    "        )\n",
    "        results['extract'] = (RelativePath(extract_file),RelativePath(extract_regions))\n",
    "    else:\n",
    "        results['extract'] = (None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate load_processed outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_counts_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_counts_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_counts_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_counts_from_bedmethyl'][motif] = load_processed.pileup_counts_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif = motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_vectors_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_vectors_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_vectors_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_vectors_from_bedmethyl'][motif] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif=motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_vectors_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    extract_file,regions_bed = results['extract']\n",
    "    if extract_file is not None and regions_bed is not None:\n",
    "        kwargs_func = filter_kwargs_for_func(load_processed.read_vectors_from_hdf5,kwargs)\n",
    "        read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "            file=extract_file,\n",
    "            **kwargs_func,\n",
    "        )        \n",
    "        read_data_dict = {}\n",
    "        # Pull out the data from the first read\n",
    "        for idx,dataset in enumerate(datasets):\n",
    "            for read_data in read_data_list:\n",
    "                read_data_dict[dataset] = read_data[idx]\n",
    "                break    \n",
    "        results['read_vectors_from_hdf5'] = read_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save text matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'megalodon_peaks_190': ({'input_file': <dimelo.test.RelativePath object at 0x2af148207a10>, 'output_name': 'megalodon_peaks_190', 'output_directory': <dimelo.test.RelativePath object at 0x2af2563c7a90>, 'regions': [<dimelo.test.RelativePath object at 0x2af24febac90>, <dimelo.test.RelativePath object at 0x2af255e3be90>], 'motifs': ['A,0', 'CG,0'], 'thresh': 190, 'window_size': 1000, 'sort_by': ['chromosome', 'read_start', 'read_name'], 'smooth_window': 1, 'title': 'megalodon_peaks_190'}, {'pileup': (<dimelo.test.RelativePath object at 0x2af2549e2450>, <dimelo.test.RelativePath object at 0x2af255e3b9d0>), 'extract': (None, None), 'pileup_counts_from_bedmethyl': {'A,0': (15443, 314114), 'CG,0': (916, 42934)}, 'pileup_vectors_from_bedmethyl': {'A,0': (array([17, 15, 17, ..., 16,  8, 26]), array([1579, 1613, 1707, ..., 1662, 1513, 1834])), 'CG,0': (array([12, 11, 10, ..., 30, 26, 46]), array([ 75,  87, 106, ..., 181, 181, 164]))}}), 'megalodon_single_190': ({'input_file': <dimelo.test.RelativePath object at 0x2af148207a10>, 'output_name': 'megalodon_single_190', 'output_directory': <dimelo.test.RelativePath object at 0x2af2563c7a90>, 'regions': 'chr14:17376348-17378348', 'motifs': ['A,0', 'CG,0'], 'thresh': 190, 'window_size': None, 'sort_by': ['chromosome', 'read_start', 'read_name'], 'smooth_window': 10, 'title': 'megalodon_single_190'}, {'pileup': (<dimelo.test.RelativePath object at 0x2af25678bb50>, <dimelo.test.RelativePath object at 0x2af257863290>), 'extract': (<dimelo.test.RelativePath object at 0x2af257867290>, <dimelo.test.RelativePath object at 0x2af25722add0>), 'pileup_counts_from_bedmethyl': {'A,0': (82, 9803), 'CG,0': (96, 1129)}, 'pileup_vectors_from_bedmethyl': {'A,0': (array([0, 0, 0, ..., 0, 0, 0]), array([ 0,  0,  8, ...,  9,  0, 15])), 'CG,0': (array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))}, 'read_vectors_from_hdf5': {'chromosome': 'chr14', 'mod_vector': array([False, False, False, ..., False, False, False]), 'motif': 'A,0', 'read_end': 17389426, 'read_name': 'c48158f0-37e5-403f-898e-a46c063ef76e', 'read_start': 17333453, 'strand': '+', 'val_vector': array([False, False, False, ..., False, False,  True]), 'region_start': 17376348, 'region_end': 17378348, 'A,0_mod_fraction': 0.0, 'CG,0_mod_fraction': 0.02127659574468085}})}\n"
     ]
    }
   ],
   "source": [
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_targets/test_matrix.pickle', 'wb') as file:\n",
    "    pickle.dump(test_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_dict = defaultdict(dict)\n",
    "# vectors_dict = defaultdict(dict)\n",
    "# binarized_reads_dict = defaultdict(dict)\n",
    "# prob_reads_dict = defaultdict(dict)\n",
    "# for motif in ['A,0','CG,0']:\n",
    "#     # Extract the total counts for the motif/regions\n",
    "#     for regions in [region,ctcf_target_regions]:\n",
    "#         counts_dict[motif][regions] = load_processed.pileup_counts_from_bedmethyl(\n",
    "#             bedmethyl_file = pileup_file,\n",
    "#             motif = motif,\n",
    "#             regions = regions\n",
    "#         )\n",
    "#     # Extract counts profiles for the motif/regions\n",
    "#     vectors_dict[motif][regions] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "#         bedmethyl_file = pileup_file,\n",
    "#         motif = motif,\n",
    "#         regions = regions,\n",
    "#         window_size = 10, # Trim/extend regions to same size    \n",
    "#     )\n",
    "#     # Extract binarized read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file, # binarized modification calls\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break    \n",
    "#     binarized_reads_dict[motif][regions] = read_data_dict\n",
    "#     # Extract probability read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file_no_thresh, # raw modification probabilities\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     # Print out the data from the first read\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break\n",
    "#     prob_reads_dict[motif][regions] = read_data_dict\n",
    "# data_struct = (counts_dict,vectors_dict,binarized_reads_dict,prob_reads_dict)\n",
    "# # Pickle the combined structure to a file\n",
    "# with open(target_paths_dict['load_processed'], 'wb') as file:\n",
    "#     pickle.dump(data_struct, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimelo_modkit_3.11",
   "language": "python",
   "name": "dimelo_modkit_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
