{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modkit found with expected version 0.2.4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from dimelo import parse_bam, load_processed\n",
    "\n",
    "# Base input and output directories\n",
    "test_data_dir = Path('./data')\n",
    "output_dir = test_data_dir / 'test_targets'\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "region = 'chr14:17376348-17378348'\n",
    "\n",
    "# Input files\n",
    "ctcf_bam_file = test_data_dir / 'ctcf_demo.sorted.bam'\n",
    "ctcf_guppy_bam_file = test_data_dir / 'winnowmap_guppy_merge_subset.updated.bam'\n",
    "ctcf_target_regions = test_data_dir / 'ctcf_demo_peak.bed'\n",
    "ctcf_off_target_regions = test_data_dir / 'ctcf_demo_not_peak.bed'\n",
    "ref_genome_file = Path('./output/chm13.draft_v1.0.fasta')\n",
    "ctcf_bam_file_updated = Path('./output/ctcf_demo.updated.bam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = {\n",
    "    'megalodon_peaks_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_peaks_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':[ctcf_target_regions,ctcf_off_target_regions],\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':1000,\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_190':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_190',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':190,\n",
    "            'window_size':None,\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    ),\n",
    "    'megalodon_single_nothresh':(\n",
    "        # input kwargs\n",
    "        {\n",
    "            'input_file':ctcf_bam_file_updated,\n",
    "            'output_name':'megalodon_single_nothresh',\n",
    "            'output_directory':output_dir,\n",
    "            'regions':region,\n",
    "            'motifs':['A,0','CG,0'],\n",
    "            'thresh':None,\n",
    "            'window_size':None,\n",
    "        },\n",
    "        # outputs dict function:values\n",
    "        {}, # populated in subsequent cells\n",
    "    )\n",
    "}\n",
    "\n",
    "# target_paths_dict = {\n",
    "#     'pileup':{\n",
    "#         'megalodon_merged_regions': (output_dir / 'megalodon_merged_regions' / 'pileup.sorted.bed.gz',output_dir / 'megalodon_merged_regions' / 'regions.processed.bed'),\n",
    "#         'megalodon_one_region': (output_dir / 'megalodon_one_region' / 'pileup.sorted.bed.gz',output_dir / 'megalodon_one_region' / 'regions.processed.bed'),\n",
    "#         'megalodon_one_region_no_threshold': (None,output_dir / 'megalodon_one_region_no_threshold' / 'regions.processed.bed')\n",
    "#     },\n",
    "#     'extract':{\n",
    "#         'megalodon_merged_regions': (output_dir / 'megalodon_merged_regions' / 'reads.combined_basemods.h5',output_dir / 'megalodon_merged_regions' / 'regions.processed.bed'),\n",
    "#         'megalodon_one_region': (output_dir / 'megalodon_one_region' / 'reads.combined_basemods.h5',output_dir / 'megalodon_one_region' / 'regions.processed.bed'),     \n",
    "#         'megalodon_one_region_no_threshold': (output_dir / 'megalodon_one_region_no_threshold' / 'reads.combined_basemods.h5',output_dir / 'megalodon_one_region_no_threshold' / 'regions.processed.bed')   \n",
    "#     },\n",
    "#     'load_processed':Path('./data/test_targets/load_processed_targets.pickle')\n",
    "\n",
    "# }\n",
    "# with open('./data/test_targets/targets_paths.pickle', 'wb') as file:\n",
    "#     pickle.dump(target_paths_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parse_bam outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e4dabcac4345bf95665131ebcfd4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137f80918a014b078d4950b5130f0b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee7b49fe9504b58b9189d4165d7eb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc84eedbefe486eb9fcf3be017a7be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1781cd60f80443c9041bac826e50d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793deed49bd342259986866a88bcf916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "No base modification threshold provided. Using adaptive threshold selection via modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b777628fc2e24c178e900ba4af85eadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee8dbbdf57246a7a56bcb355088875f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed4078baf9c457eb03a543a08741c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    pileup_file, pileup_regions = parse_bam.pileup(\n",
    "        **kwargs,\n",
    "        ref_genome = ref_genome_file,\n",
    "    )\n",
    "    results['pileup'] = (pileup_file,pileup_regions)\n",
    "\n",
    "# pileup_file, pileup_regions = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_merged_regions',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=[ctcf_target_regions,ctcf_off_target_regions],\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=1000,\n",
    "# )\n",
    "# pileup_file_one, pileup_regions_one = parse_bam.pileup(\n",
    "#     input_file=ctcf_bam_file_updated,\n",
    "#     output_name='megalodon_one_region',\n",
    "#     ref_genome=ref_genome_file,\n",
    "#     output_directory=output_dir,\n",
    "#     regions=region,\n",
    "#     motifs=['A,0','CG,0'],\n",
    "#     thresh=190,\n",
    "#     window_size=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "Modification threshold of 190 assumed to be for range 0-255. 190/255=0.7450980392156863 will be sent to modkit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f3a15336f24906b0e0c80d7a1f6f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac33164293354bbeaa99bad000198842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6345be9d044c26b3a54f406c876e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f390128a9810473a9f279f346b312145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.A,0.txt into reads.combined_basemods.h5, new size 24   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a55a4f22d54cbbbce12fe171e48140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0105c6603d4b4fbba5bab2d93498a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1b4be2db274fc09b67cfd007c1e390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97c1b63c4b74580af35c2b4cb12a4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.CG,0.txt into reads.combined_basemods.h5, new size 48   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specified number of cores requested. 8 available on machine, allocating all.\n",
      "No valid base modification threshold provided. Raw probs will be saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a32894cbd20401e8abf13402f25d44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ec2666c0144fc2bcbbbc90664034ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72dcc4e59b44e73801188c0f3463c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cee0e864fe4df89119d53ad3649f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.A,0.txt into reads.combined_basemods.h5, new size 24   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4062902f3b48c19db1d2f398b3f091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Preprocessing   0% | 00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddfe7634652485792f0e7520ea90d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Processing ctcf_demo.updated.bam   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3809f3fda39446f193497a45fd12959b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          |    0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3156e377d9b45eb9e1e0d198ce62f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          | Transferring 24 from reads.CG,0.txt into reads.combined_basemods.h5, new size 48   0% | 00:00<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    if kwargs['regions']==region: # for now, we only want to extract with the single region due to output file size\n",
    "        extract_file, extract_regions = parse_bam.extract(\n",
    "            **kwargs,\n",
    "            ref_genome = ref_genome_file,\n",
    "        )\n",
    "        results['extract'] = (extract_file,extract_regions)\n",
    "    else:\n",
    "        results['extract'] = (None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate load_processed outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_counts_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "def filter_kwargs_for_func(func, kwargs):\n",
    "    func_sig = signature(func)\n",
    "    allowed_args = set(func_sig.parameters)\n",
    "    filtered_kwargs = {k: v for k, v in kwargs.items() if k in allowed_args}\n",
    "    return filtered_kwargs\n",
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_counts_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_counts_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_counts_from_bedmethyl'][motif] = load_processed.pileup_counts_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif = motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pileup_vectors_from_bedmethyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    results['pileup_vectors_from_bedmethyl'] = {}\n",
    "    kwargs_func = filter_kwargs_for_func(load_processed.pileup_vectors_from_bedmethyl,kwargs)\n",
    "    for motif in kwargs['motifs']:\n",
    "        results['pileup_vectors_from_bedmethyl'][motif] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "            bedmethyl_file = results['pileup'][0],\n",
    "            **kwargs_func,\n",
    "            motif=motif,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_vectors_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kwargs,results in test_matrix.values():\n",
    "    extract_file,regions_bed = results['extract']\n",
    "    if extract_file is not None and regions_bed is not None:\n",
    "        kwargs_func = filter_kwargs_for_func(load_processed.read_vectors_from_hdf5,kwargs)\n",
    "        read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "            file=extract_file, # binarized modification calls\n",
    "            **kwargs_func,\n",
    "            sort_by = ['chromosome','read_start','read_name']\n",
    "        )        \n",
    "        read_data_dict = {}\n",
    "        # Print out the data from the first read\n",
    "        for idx,dataset in enumerate(datasets):\n",
    "            for read_data in read_data_list:\n",
    "                read_data_dict[dataset] = read_data[idx]\n",
    "                break    \n",
    "        results['read_vectors_from_hdf5'] = read_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save text matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_targets/text_matrix.pickle', 'wb') as file:\n",
    "    pickle.dump(test_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_dict = defaultdict(dict)\n",
    "# vectors_dict = defaultdict(dict)\n",
    "# binarized_reads_dict = defaultdict(dict)\n",
    "# prob_reads_dict = defaultdict(dict)\n",
    "# for motif in ['A,0','CG,0']:\n",
    "#     # Extract the total counts for the motif/regions\n",
    "#     for regions in [region,ctcf_target_regions]:\n",
    "#         counts_dict[motif][regions] = load_processed.pileup_counts_from_bedmethyl(\n",
    "#             bedmethyl_file = pileup_file,\n",
    "#             motif = motif,\n",
    "#             regions = regions\n",
    "#         )\n",
    "#     # Extract counts profiles for the motif/regions\n",
    "#     vectors_dict[motif][regions] = load_processed.pileup_vectors_from_bedmethyl(\n",
    "#         bedmethyl_file = pileup_file,\n",
    "#         motif = motif,\n",
    "#         regions = regions,\n",
    "#         window_size = 10, # Trim/extend regions to same size    \n",
    "#     )\n",
    "#     # Extract binarized read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file, # binarized modification calls\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break    \n",
    "#     binarized_reads_dict[motif][regions] = read_data_dict\n",
    "#     # Extract probability read vectors for the motif/regions\n",
    "#     read_data_list, datasets, _ = load_processed.read_vectors_from_hdf5(\n",
    "#         file=extract_file_no_thresh, # raw modification probabilities\n",
    "#         regions=regions,\n",
    "#         motifs=[motif],\n",
    "#         sort_by = ['chromosome','read_start','read_name']\n",
    "#     )\n",
    "#     read_data_dict = {}\n",
    "#     # Print out the data from the first read\n",
    "#     for idx,dataset in enumerate(datasets):\n",
    "#         for read_data in read_data_list:\n",
    "#             read_data_dict[dataset] = read_data[idx]\n",
    "#             break\n",
    "#     prob_reads_dict[motif][regions] = read_data_dict\n",
    "# data_struct = (counts_dict,vectors_dict,binarized_reads_dict,prob_reads_dict)\n",
    "# # Pickle the combined structure to a file\n",
    "# with open(target_paths_dict['load_processed'], 'wb') as file:\n",
    "#     pickle.dump(data_struct, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimelo_modkit_parsing",
   "language": "python",
   "name": "dimelo_modkit_parsing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
